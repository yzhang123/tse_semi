{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ad561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:18:17.401490Z",
     "start_time": "2021-11-04T15:18:17.272899Z"
    }
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9174a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:18:17.841600Z",
     "start_time": "2021-11-04T15:18:17.824299Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b42673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:18:18.498501Z",
     "start_time": "2021-11-04T15:18:18.482458Z"
    }
   },
   "outputs": [],
   "source": [
    "def sound( x, rate=8000, label=''):\n",
    "    from IPython.display import display, Audio, HTML\n",
    "    if label is '':\n",
    "        display( Audio( x, rate=rate))\n",
    "    else:\n",
    "        display( HTML( \n",
    "        '<style> table, th, td {border: 0px; }</style> <table><tr><td>' + label + \n",
    "        '</td><td>' + Audio( x, rate=rate)._repr_html_()[3:] + '</td></tr></table>'\n",
    "        ))\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa059f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:18:25.031923Z",
     "start_time": "2021-11-04T15:18:23.536630Z"
    }
   },
   "outputs": [],
   "source": [
    "emb_hyp = {\n",
    "    'input_size': 80,\n",
    "    'channels': [1024, 1024, 1024, 1024, 3072],\n",
    "    'kernel_sizes': [5, 3, 3, 3, 1],\n",
    "    'dilations': [1, 2, 3, 4, 1],\n",
    "    'groups': [1, 1, 1, 1, 1],\n",
    "    'attention_channels': 128,\n",
    "    'lin_neurons': 192,\n",
    "}\n",
    "\n",
    "from spid_modules.ECAPA_TDNN import ECAPA_TDNN\n",
    "embedder = ECAPA_TDNN(**emb_hyp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc51815",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:18:36.406953Z",
     "start_time": "2021-11-04T15:18:36.257896Z"
    }
   },
   "outputs": [],
   "source": [
    "import speechbrain\n",
    "pretrainer = speechbrain.utils.parameter_transfer.Pretrainer(collect_in='./emb_test', loadables={'embedding_model': embedder},\n",
    "                                                             paths={'embedding_model': '/mnt/data/zhepei/outputs/ecapa_augment_8k/1986/save/CKPT+2021-10-30+08-02-06+00/embedding_model.ckpt'})\n",
    "pretrainer.collect_files()\n",
    "pretrainer.load_collected('cpu')\n",
    "embedder.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072e0f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:18:55.438955Z",
     "start_time": "2021-11-04T15:18:55.411428Z"
    }
   },
   "outputs": [],
   "source": [
    "from speechbrain.lobes.features import Fbank\n",
    "compute_features = Fbank(sample_rate=8000, n_mels=80)\n",
    "mean_var_norm = speechbrain.processing.features.InputNormalization(\n",
    "    norm_type='sentence',\n",
    "    std_norm=False\n",
    ")\n",
    "mean_var_norm_emb = speechbrain.processing.features.InputNormalization(\n",
    "    norm_type='global',\n",
    "    std_norm=False\n",
    ")\n",
    "mean_var_norm.eval()\n",
    "mean_var_norm_emb.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3342187",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:19:03.917596Z",
     "start_time": "2021-11-04T15:19:03.897429Z"
    }
   },
   "outputs": [],
   "source": [
    "hyp = {\n",
    "    'sample_rate': 8000,\n",
    "    'training_signal_len': 40000,\n",
    "    'train_dataloader_opts': {\n",
    "        'batch_size': 1,\n",
    "        'num_workers': 0,\n",
    "    },\n",
    "    'valid_dataloader_opts': {\n",
    "        'batch_size': 1,\n",
    "        'num_workers': 0,\n",
    "    },\n",
    "    'data_folder': '/mnt/data/wham/wham_original',\n",
    "    'wsj_folder': '/mnt/data/wsj0.8k',\n",
    "    'base_folder_dm_info_list': [\n",
    "        {\n",
    "            'path': '/mnt/data/wsj0.8k/si_tr_s/',\n",
    "            'ext': 'wav',\n",
    "            'type': 'clean',\n",
    "        }\n",
    "    ],\n",
    "    'data_clean_prob': 1.,\n",
    "    \n",
    "#     'train_txtpath': '/mnt/data/Speech/wsj_tse/mix_2_spk_tr_extr.txt',\n",
    "#     'train_wham_folder': '/mnt/data/wham/wham_original/wav8k/min/tr',\n",
    "    'train_data': '/mnt/data/zhepei/outputs/sb_tse/results/2021-10-11+21-30-05+seed_1234+xformer-wham/save/wham_tse_tr.csv',\n",
    "    'valid_data': '/mnt/data/zhepei/outputs/sb_tse/results/2021-10-27+03-53-37+seed_1234+xformer-wham-pre/save/wham_tse_tt.csv',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37046c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:19:04.183231Z",
     "start_time": "2021-11-04T15:19:04.142730Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from speechbrain.dataio.batch import PaddedBatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3e7e0",
   "metadata": {},
   "source": [
    "# Test Dynamic mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e13eb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:20:43.890766Z",
     "start_time": "2021-11-04T15:20:42.102707Z"
    }
   },
   "outputs": [],
   "source": [
    "from data.wham_data_utils import dynamic_mixing_prep\n",
    "train_dl = dynamic_mixing_prep(hyp, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7df6fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:38:22.447328Z",
     "start_time": "2021-11-01T19:38:22.426377Z"
    }
   },
   "outputs": [],
   "source": [
    "def listen_batch(batch):\n",
    "    mix = batch['mix_sig'].data\n",
    "    s1 = batch['s1_sig'].data\n",
    "    s2 = batch['s2_sig'].data\n",
    "    enr = batch['enr_sig'].data\n",
    "    noise = batch['noise_sig'].data\n",
    "    diff = mix - s1 - s2 - noise\n",
    "    print(abs(mix).max())\n",
    "    print((diff**2).mean())\n",
    "    sound(mix[0].numpy(), rate=hyp['sample_rate'], label='mix')\n",
    "    sound(s1[0].numpy(), rate=hyp['sample_rate'], label='s1')\n",
    "    sound(s2[0].numpy(), rate=hyp['sample_rate'], label='s2')\n",
    "    sound(enr[0].numpy(), rate=hyp['sample_rate'], label='enr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bffb5ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:19:24.413905Z",
     "start_time": "2021-11-04T15:19:24.380164Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cos_sim(v1, v2):\n",
    "    return (v1 * v2).sum() / (torch.norm(v1) * torch.norm(v2) + 1e-8)\n",
    "\n",
    "def compute_embedding(wavs, wav_lens):\n",
    "    \"\"\"Compute speaker embeddings.\n",
    "    Arguments\n",
    "    ---------\n",
    "    wavs : Torch.Tensor\n",
    "        Tensor containing the speech waveform (batch, time).\n",
    "        Make sure the sample rate is fs=16000 Hz.\n",
    "    wav_lens: Torch.Tensor\n",
    "        Tensor containing the relative length for each sentence\n",
    "        in the length (e.g., [0.8 0.6 1.0])\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        scales = 0.9 / torch.amax(torch.abs(wavs), dim=-1, keepdim=True)\n",
    "        wavs = wavs * scales\n",
    "        feats = compute_features(wavs)\n",
    "        feats = mean_var_norm(feats, wav_lens)\n",
    "        embeddings = embedder(feats, wav_lens)\n",
    "        embeddings = mean_var_norm_emb(\n",
    "            embeddings, torch.ones(embeddings.shape[0]).to(embeddings.device)\n",
    "        )\n",
    "        embeddings = embeddings / (1e-8 + torch.norm(embeddings, p=2, dim=-1, keepdim=True))\n",
    "    return embeddings.squeeze(1)\n",
    "\n",
    "def check_emb(batch):\n",
    "    s1 = batch['s1_sig'].data\n",
    "    s2 = batch['s2_sig'].data\n",
    "    enr = batch['enr_sig'].data\n",
    "    s1_emb = compute_embedding(s1, batch['s1_sig'].lengths)\n",
    "    s2_emb = compute_embedding(s2, batch['s2_sig'].lengths)\n",
    "    enr_emb = compute_embedding(enr, batch['enr_sig'].lengths)\n",
    "    pos_sim = compute_cos_sim(s1_emb[0], enr_emb[0]).item()\n",
    "    neg_sim = compute_cos_sim(s2_emb[0], enr_emb[0]).item()\n",
    "    if np.isnan(pos_sim - neg_sim).any():\n",
    "        pdb.set_trace()\n",
    "    print('Positive sim: {} -- Negative sim: {} -- diff: {}'.format(pos_sim, neg_sim, pos_sim-neg_sim))\n",
    "\n",
    "# def check_emb_noise(batch):\n",
    "#     s1 = batch['s1_sig'].data\n",
    "#     s2 = batch['s2_sig'].data\n",
    "#     enr = batch['enr_sig'].data\n",
    "#     noise = batch['noise_sig'].data\n",
    "#     s1_emb = embedder(s1+noise)\n",
    "#     s2_emb = embedder(s2+noise)\n",
    "#     min_len = min(enr.shape[-1], noise.shape[-1])\n",
    "#     enr_emb = embedder(enr[..., :min_len]+noise[..., :min_len])\n",
    "#     pos_sim = compute_cos_sim(s1_emb[0], enr_emb[0]).item()\n",
    "#     neg_sim = compute_cos_sim(s2_emb[0], enr_emb[0]).item()\n",
    "#     print('Positive sim: {} -- Negative sim: {} -- diff: {}'.format(pos_sim, neg_sim, pos_sim-neg_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d1f23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:38:23.100085Z",
     "start_time": "2021-11-01T19:38:23.008439Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_dl):  \n",
    "    if i == 1:\n",
    "        listen_batch(batch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f1213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T19:38:40.603636Z",
     "start_time": "2021-11-01T19:38:23.575377Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_dl):\n",
    "    with torch.no_grad():\n",
    "        check_emb(batch)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aa1fe7",
   "metadata": {},
   "source": [
    "# Test static mixing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8efa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T21:01:05.907946Z",
     "start_time": "2021-11-01T21:01:05.842857Z"
    }
   },
   "outputs": [],
   "source": [
    "from data.wham_data_utils import static_data_prep\n",
    "valid_ds = static_data_prep(hyp, 'valid')\n",
    "valid_dl = torch.utils.data.DataLoader(\n",
    "        valid_ds,\n",
    "        batch_size=hyp[\"valid_dataloader_opts\"][\"batch_size\"],\n",
    "        num_workers=hyp[\"valid_dataloader_opts\"][\"num_workers\"],\n",
    "        collate_fn=PaddedBatch,\n",
    "        worker_init_fn=lambda x: np.random.seed(\n",
    "            int.from_bytes(os.urandom(4), \"little\") + x\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209344a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T20:27:50.859263Z",
     "start_time": "2021-11-01T20:27:50.810695Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(valid_dl):  \n",
    "    if i == 1:\n",
    "        listen_batch(batch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0d7dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T21:01:25.953973Z",
     "start_time": "2021-11-01T21:01:09.973331Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(valid_dl):  \n",
    "    check_emb(batch)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd6d98a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T21:04:31.621299Z",
     "start_time": "2021-11-01T21:04:15.696861Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(valid_dl):  \n",
    "    check_emb(batch)\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c292e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch110",
   "language": "python",
   "name": "pytorch110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
